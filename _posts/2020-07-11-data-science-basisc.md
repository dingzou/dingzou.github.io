---
title: Data Science Basics
---

There are three Python library that is widely adopted in data science communities.
 - numPy (Numerical Python) is a powerful, and extensively used, library for storage and calculations. For example, this library contains basic linear algebra function, Fourier transfers, and advance random number capabilities. It can also be use to load data to Python and export from it.
 - Pandas is a library that you can't avoid when working with Pythong on a data science project. It is a powerful tool for data wrangling, a process required to prepare your data so that it can be actually consumed for analysis and model building.
 - Scikit Learn is an easy to use library for Machine Learning. It comes with a variety of efficient tools for machine learning and statistical modeling: it provides classification models (e.g., Support Vector Machines, Random Forests, Decision Trees), Regression Analysis (e.g., Linear Regression, Ridge Regression, Logistic Regression), Clustering methods (e.g, k-means), data reduction methods (e.g., Principal Component Analysis, feature selection), model tuning, and selection with features like grid search, cross-validation.
 - Matplotlib is widely used for data visualization like for plotting histograms, line plots, and heat plots.
 - Seaborn is another great library for creating attractive and information rich graphics. Its goal is to make data exploration and understanding easier, and it does it very well. Seaborn is based on Matplotlib which is its child, basically.






Presto, Hive, Spark
> "Data scientists and machine learning engineers at Pinterest found themselves hitting major challenges with existing tools. Hive and Presto were readily accessible tools for large scale data transformations, but complex logic is difficult to write in SQL. Some engineers wrote complex logics in Cascading or Scala Spark jobs, but these have a steep learning curve and take significantly more time to learn and build jobs. Furthermore, data scientists and machine learning engineers often trained models in a small-scale notebook environment, but they lacked the tools to perform large-scale inference."


source: Grokking Data Science on educative.io
source: Empowering Pinterest Data Scientists and Machine Learning Engineers with PySpark
